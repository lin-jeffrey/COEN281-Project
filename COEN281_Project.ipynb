{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of Fake New using Ensemble Methods\n",
    "### Jeffrey Lin Alex Te\n",
    "#### Santa Clara University\n",
    "#### COEN281 Term Project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/st/kmr27w2j34n69dljmyjl7dnr0000gp/T/ipykernel_839/344007209.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset\n",
    "Here we will inport a dataset taken from: https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing fake news dataset\n",
    "df_false = pd.read_csv(\"Fake.csv\")\n",
    "df_false.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing true news dataset\n",
    "df_true = pd.read_csv(\"True.csv\")\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove brackets since true dataset has random brackets with the time in it \n",
    "# remove entries with empty features\n",
    "# remove publisher identification (reuters)\n",
    "# tbd\n",
    "\n",
    "del df_true['subject']\n",
    "del df_true['date']\n",
    "del df_false['subject']\n",
    "del df_false['date']\n",
    "\n",
    "for index, row in df_true.iterrows():\n",
    "    row_text = row['text']\n",
    "    if \") - \" in row_text:\n",
    "        row_text = row_text.split(\") - \")[1]\n",
    "        \n",
    "    if bool(re.search('\\[\\d* \\w*\\]', row_text)):\n",
    "        row_text = \" \".join(re.split('\\[\\d* \\w*\\]', row_text))\n",
    "        \n",
    "    row['text'] = row_text\n",
    "\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining True/False Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating labels for true(1)/false(0)\n",
    "df_true['category'] = 1\n",
    "df_false['category'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat datasets into one\n",
    "df = pd.concat([df_true,df_false]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset balance\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training/Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are splitting the training and testing dataset here since if we do it later we get a memory error\n",
    "y = df[\"category\"] \n",
    "X = df[\"text\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "pd.Series(y_train).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtrain = pd.DataFrame(X_train)\n",
    "df_xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtest = pd.DataFrame(X_test)\n",
    "df_xtest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert analysis here\n",
    "# point of question\n",
    "# first check to see if the data is balance (i.e. there are the same number of true articles as there are false)\n",
    "\n",
    "num_true_articles = len(df_true.index)\n",
    "num_false_articles = len(df_false.index)\n",
    "\n",
    "num_articles = num_true_articles if num_true_articles <= num_false_articles else num_false_articles\n",
    "\n",
    "#num_articles hold the smaller of the two datasets (that way we are comparing the same number of articles)\n",
    "#time to count the number of words inside each.\n",
    "\n",
    "true_dataset_num_words_per_article = {}\n",
    "true_dataset_words = {}\n",
    "false_dataset_num_words_per_article = {}\n",
    "false_dataset_words = {}\n",
    "\n",
    "for index, row in df_true.iterrows():\n",
    "    if index == num_articles:\n",
    "        break\n",
    "    else:\n",
    "        row_text = row['text']\n",
    "        string_list = row_text.split()\n",
    "        true_dataset_num_words_per_article[f\"Article{index}\"] = len(string_list)\n",
    "        for word in string_list:\n",
    "            true_dataset_words[word] = string_list.count(word)\n",
    "\n",
    "for index, row in df_false.iterrows():\n",
    "    if index == num_articles:\n",
    "        break\n",
    "    else:\n",
    "        row_text = row['text']\n",
    "        string_list = row_text.split()\n",
    "        false_dataset_num_words_per_article[f\"Article{index}\"] = len(string_list)\n",
    "        for word in string_list:\n",
    "            false_dataset_words[word] = string_list.count(word)\n",
    "\n",
    "print(f\"Num words in each of the true dataset: {true_dataset_num_words_per_article}\")\n",
    "print(f\"Words in the true dataset (across all {num_articles} articles): {true_dataset_words}\")\n",
    "\n",
    "print(f\"Num words in each of the false dataset: {false_dataset_num_words_per_article}\")\n",
    "print(f\"Words in the false dataset (across all {num_articles} articles): {false_dataset_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove puncutation from text\n",
    "def clean_punc(inputString):\n",
    "    cleaned = re.sub(r'[?|!|\\'|#]', r'', inputString)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]', r' ', cleaned)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtrain[\"text\"] = df_xtrain.apply(lambda row: clean_punc(row[\"text\"]), axis=1)\n",
    "df_xtest[\"text\"] = df_xtest.apply(lambda row: clean_punc(row[\"text\"]), axis=1)\n",
    "\n",
    "#df[\"text\"] = df.apply(lambda row: clean_punc(row[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase\n",
    "def lower_case(inputString):\n",
    "    return inputString.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtrain[\"text\"] = df_xtrain.apply(lambda row: lower_case(row[\"text\"]), axis=1)\n",
    "df_xtest[\"text\"] = df_xtest.apply(lambda row: lower_case(row[\"text\"]), axis=1)\n",
    "\n",
    "#df[\"text\"] = df.apply(lambda row: lower_case(row[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this to download wordnet library (one time download)\n",
    "\"\"\"\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization groups words with the same base meaning together\n",
    "# i.e. studies studying cries cry -> study studying cry cry\n",
    "def lemmatization(inputString):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = []\n",
    "    for word in inputString.split():\n",
    "        words.append(lemmatizer.lemmatize(word))\n",
    "    output = \" \".join(words)\n",
    "    return output\n",
    "\n",
    "# test\n",
    "#print(lemmatization(\"studies studying cries cry\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply lemmatization to text\n",
    "df_xtrain[\"text\"] = df_xtrain.apply(lambda row: lemmatization(row[\"text\"]), axis=1)\n",
    "df_xtest[\"text\"] = df_xtest.apply(lambda row: lemmatization(row[\"text\"]), axis=1)\n",
    "\n",
    "#df[\"text\"] = df.apply(lambda row: lemmatization(row[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words that don't provide additional meaning to text\n",
    "def stopword_removal(inputString):\n",
    "    sw = stopwords.words('english')\n",
    "    words = [word for word in inputString.split() if word not in sw]\n",
    "    output = \" \".join(words)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply stopword removal to text\n",
    "df_xtrain[\"text\"] = df_xtrain.apply(lambda row: stopword_removal(row[\"text\"]), axis=1)\n",
    "df_xtest[\"text\"] = df_xtest.apply(lambda row: stopword_removal(row[\"text\"]), axis=1)\n",
    "\n",
    "#df[\"text\"] = df.apply(lambda row: stopword_removal(row[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf vectorizer\n",
    "# we must .fit() the vectorizer on the training dataset so that when we use .transform()\n",
    "# the dimension of the resulting df is the same for train and test (it uses the word corpus of training set)\n",
    "# output_train/test is the sparce matrix, df_xtrain/testvectorized is just for display\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(df_xtrain[\"text\"]) \n",
    "output_train = tfidf.transform(df_xtrain[\"text\"])\n",
    "df_xtrainvectorized = pd.DataFrame(output_train.toarray(), columns=tfidf.get_feature_names())\n",
    "df_xtrainvectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = tfidf.transform(df_xtest[\"text\"])\n",
    "df_xtest_vectorized = pd.DataFrame(output_test.toarray(), columns=tfidf.get_feature_names())\n",
    "df_xtest_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: there is a lot of garbage values\n",
    "\n",
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train needs to be a list of the training data.\n",
    "train_data = [X_train]\n",
    "labels = y_train\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(train_data, labels)\n",
    "\n",
    "#loop through the testing data here\n",
    "# https://scikit-learn.org/stable/modules/tree.html\n",
    "# i needs to be 1 single list and in the square bracket\n",
    "# for i in ___\n",
    "#   clf.predict([i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model\n",
    "\n",
    "rf_regr = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "rf_regr.fit(output_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultRF = rf_regr.predict(output_test)\n",
    "resultRF = resultRF.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the confusion matrix\n",
    "print('Confusion Matrix - Random Forest')\n",
    "print(pd.crosstab(y_test, resultRF, rownames = ['True'], colnames = ['Predicted'], margins = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score - Random Forest:')\n",
    "print(f1_score(y_test, resultRF, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting and predicting using gradient boosting\n",
    "xgb = XGBClassifier(n_estimators=20, random_state=0)\n",
    "xgb.fit(output_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultXGB = xgb.predict(output_test)\n",
    "resultXGB = resultXGB.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the confusion matrix\n",
    "print('Confusion Matrix - Random Forest')\n",
    "print(pd.crosstab(y_test, resultRF, rownames = ['True'], colnames = ['Predicted'], margins = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score - XGBClassifier:')\n",
    "print(f1_score(y_test, resultXGB, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
