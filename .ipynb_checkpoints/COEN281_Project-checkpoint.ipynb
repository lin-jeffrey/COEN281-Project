{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of Fake News using Ensemble Methods\n",
    "### Jeffrey Lin Alex Te\n",
    "#### Santa Clara University\n",
    "#### COEN281 Term Project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset\n",
    "Here we will inport a dataset taken from: https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing fake news dataset\n",
    "df_false = pd.read_csv(\"Fake.csv\")\n",
    "df_false.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing true news dataset\n",
    "df_true = pd.read_csv(\"True.csv\")\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>The head of a conservative Republican faction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>Transgender people will be allowed for the fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>The special counsel investigation of links bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>Trump campaign adviser George Papadopoulos tol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>President Donald Trump called on the U.S. Post...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text  \n",
       "0  The head of a conservative Republican faction ...  \n",
       "1  Transgender people will be allowed for the fir...  \n",
       "2  The special counsel investigation of links bet...  \n",
       "3  Trump campaign adviser George Papadopoulos tol...  \n",
       "4  President Donald Trump called on the U.S. Post...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove brackets since true dataset has random brackets with the time in it \n",
    "# remove entries with empty features\n",
    "# remove publisher identification (reuters)\n",
    "# tbd\n",
    "\n",
    "del df_true['subject']\n",
    "del df_true['date']\n",
    "del df_false['subject']\n",
    "del df_false['date']\n",
    "\n",
    "for index, row in df_true.iterrows():\n",
    "    row_text = row['text']\n",
    "    if \") - \" in row_text:\n",
    "        row_text = row_text.split(\") - \")[1]\n",
    "        \n",
    "    if bool(re.search('\\[\\d* \\w*\\]', row_text)):\n",
    "        row_text = \" \".join(re.split('\\[\\d* \\w*\\]', row_text))\n",
    "        \n",
    "    row['text'] = row_text\n",
    "\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining True/False Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating labels for true(1)/false(0)\n",
    "df_true['category'] = 1\n",
    "df_false['category'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat datasets into one\n",
    "df = pd.concat([df_true,df_false]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>The head of a conservative Republican faction ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>Transgender people will be allowed for the fir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>The special counsel investigation of links bet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>Trump campaign adviser George Papadopoulos tol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>President Donald Trump called on the U.S. Post...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23479</th>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      As U.S. budget fight looms, Republicans flip t...   \n",
       "1      U.S. military to accept transgender recruits o...   \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      FBI Russia probe helped by Australian diplomat...   \n",
       "4      Trump wants Postal Service to charge 'much mor...   \n",
       "...                                                  ...   \n",
       "23476  McPain: John McCain Furious That Iran Treated ...   \n",
       "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "23479  How to Blow $700 Million: Al Jazeera America F...   \n",
       "23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                    text  category  \n",
       "0      The head of a conservative Republican faction ...         1  \n",
       "1      Transgender people will be allowed for the fir...         1  \n",
       "2      The special counsel investigation of links bet...         1  \n",
       "3      Trump campaign adviser George Papadopoulos tol...         1  \n",
       "4      President Donald Trump called on the U.S. Post...         1  \n",
       "...                                                  ...       ...  \n",
       "23476  21st Century Wire says As 21WIRE reported earl...         0  \n",
       "23477  21st Century Wire says It s a familiar theme. ...         0  \n",
       "23478  Patrick Henningsen  21st Century WireRemember ...         0  \n",
       "23479  21st Century Wire says Al Jazeera America will...         0  \n",
       "23480  21st Century Wire says As 21WIRE predicted in ...         0  \n",
       "\n",
       "[44898 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23481\n",
       "1    21417\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset balance\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training/Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we are splitting the training and testing dataset here since if we do it later we get a memory error\n",
    "y = df[\"category\"] \n",
    "X = df[\"text\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "pd.Series(y_train).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>Delaying or blocking a planned transition of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12191</th>\n",
       "      <td>Hillary Clinton on Thursday decried the spread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8385</th>\n",
       "      <td>Mylan NV’s move on Thursday to expand discount...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>Turkey took the Kurdish television channel Rud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6690</th>\n",
       "      <td>In a veiled warning to U.S. President-elect Do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "8159   Delaying or blocking a planned transition of o...\n",
       "12191  Hillary Clinton on Thursday decried the spread...\n",
       "8385   Mylan NV’s move on Thursday to expand discount...\n",
       "19099  Turkey took the Kurdish television channel Rud...\n",
       "6690   In a veiled warning to U.S. President-elect Do..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xtrain = pd.DataFrame(X_train)\n",
    "df_xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>Wayde van Niekerk duly qualified for the World...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14819</th>\n",
       "      <td>Ukraine is puzzled by the lack of a U.S. respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>U.S. President Donald Trump said on Friday tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9013</th>\n",
       "      <td>Having stayed close to the Obama family for bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16082</th>\n",
       "      <td>President Trump is scheduled to deliver a hist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "2283   Wayde van Niekerk duly qualified for the World...\n",
       "14819  Ukraine is puzzled by the lack of a U.S. respo...\n",
       "12196  U.S. President Donald Trump said on Friday tha...\n",
       "9013   Having stayed close to the Obama family for bo...\n",
       "16082  President Trump is scheduled to deliver a hist..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xtest = pd.DataFrame(X_test)\n",
    "df_xtest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# point of question\n",
    "# first check to see if the data is balance (i.e. there are the same number of true articles as there are false)\n",
    "\n",
    "num_true_articles = len(df_true.index)\n",
    "num_false_articles = len(df_false.index)\n",
    "\n",
    "num_articles = num_true_articles if num_true_articles <= num_false_articles else num_false_articles\n",
    "\n",
    "#num_articles hold the smaller of the two datasets (that way we are comparing the same number of articles)\n",
    "#time to count the number of words inside each.\n",
    "\n",
    "true_dataset_num_words_per_article = {}\n",
    "true_dataset_words = {}\n",
    "false_dataset_num_words_per_article = {}\n",
    "false_dataset_words = {}\n",
    "\n",
    "for index, row in df_true.iterrows():\n",
    "    if index == num_articles:\n",
    "        break\n",
    "    else:\n",
    "        row_text = row['text']\n",
    "        string_list = row_text.split()\n",
    "        true_dataset_num_words_per_article[f\"Article{index}\"] = len(string_list)\n",
    "        for word in string_list:\n",
    "            true_dataset_words[word] = string_list.count(word)\n",
    "\n",
    "for index, row in df_false.iterrows():\n",
    "    if index == num_articles:\n",
    "        break\n",
    "    else:\n",
    "        row_text = row['text']\n",
    "        string_list = row_text.split()\n",
    "        false_dataset_num_words_per_article[f\"Article{index}\"] = len(string_list)\n",
    "        for word in string_list:\n",
    "            false_dataset_words[word] = string_list.count(word)\n",
    "\n",
    "print(f\"Num words in each of the true dataset: {true_dataset_num_words_per_article}\")\n",
    "print(f\"Words in the true dataset (across all {num_articles} articles): {true_dataset_words}\")\n",
    "\n",
    "print(f\"Num words in each of the false dataset: {false_dataset_num_words_per_article}\")\n",
    "print(f\"Words in the false dataset (across all {num_articles} articles): {false_dataset_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove puncutation from text\n",
    "def clean_punc(inputString):\n",
    "    cleaned = re.sub(r'[?|!|\\'|#]', r'', inputString)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]', r' ', cleaned)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtrain[\"text\"] = df_xtrain.apply(lambda row: clean_punc(row[\"text\"]), axis=1)\n",
    "df_xtest[\"text\"] = df_xtest.apply(lambda row: clean_punc(row[\"text\"]), axis=1)\n",
    "\n",
    "#df[\"text\"] = df.apply(lambda row: clean_punc(row[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase\n",
    "def lower_case(inputString):\n",
    "    return inputString.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xtrain[\"text\"] = df_xtrain.apply(lambda row: lower_case(row[\"text\"]), axis=1)\n",
    "df_xtest[\"text\"] = df_xtest.apply(lambda row: lower_case(row[\"text\"]), axis=1)\n",
    "\n",
    "#df[\"text\"] = df.apply(lambda row: lower_case(row[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport nltk\\nimport ssl\\n\\ntry:\\n    _create_unverified_https_context = ssl._create_unverified_context\\nexcept AttributeError:\\n    pass\\nelse:\\n    ssl._create_default_https_context = _create_unverified_https_context\\n\\nnltk.download('wordnet')\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use this to download wordnet library (one time download)\n",
    "\"\"\"\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization groups words with the same base meaning together\n",
    "# i.e. studies studying cries cry -> study studying cry cry\n",
    "def lemmatization(inputString):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = []\n",
    "    for word in inputString.split():\n",
    "        words.append(lemmatizer.lemmatize(word))\n",
    "    output = \" \".join(words)\n",
    "    return output\n",
    "\n",
    "# test\n",
    "#print(lemmatization(\"studies studying cries cry\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply lemmatization to text\n",
    "df_xtrain[\"text\"] = df_xtrain.apply(lambda row: lemmatization(row[\"text\"]), axis=1)\n",
    "df_xtest[\"text\"] = df_xtest.apply(lambda row: lemmatization(row[\"text\"]), axis=1)\n",
    "\n",
    "#df[\"text\"] = df.apply(lambda row: lemmatization(row[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words that don't provide additional meaning to text\n",
    "def stopword_removal(inputString):\n",
    "    sw = stopwords.words('english')\n",
    "    words = [word for word in inputString.split() if word not in sw]\n",
    "    output = \" \".join(words)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply stopword removal to text\n",
    "df_xtrain[\"text\"] = df_xtrain.apply(lambda row: stopword_removal(row[\"text\"]), axis=1)\n",
    "df_xtest[\"text\"] = df_xtest.apply(lambda row: stopword_removal(row[\"text\"]), axis=1)\n",
    "\n",
    "#df[\"text\"] = df.apply(lambda row: stopword_removal(row[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>delaying blocking planned transition oversight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12191</th>\n",
       "      <td>hillary clinton thursday decried spread fake n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8385</th>\n",
       "      <td>mylan nv’s move thursday expand discount progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>turkey took kurdish television channel rudaw s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6690</th>\n",
       "      <td>veiled warning u president-elect donald trump ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "8159   delaying blocking planned transition oversight...\n",
       "12191  hillary clinton thursday decried spread fake n...\n",
       "8385   mylan nv’s move thursday expand discount progr...\n",
       "19099  turkey took kurdish television channel rudaw s...\n",
       "6690   veiled warning u president-elect donald trump ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>wayde van niekerk duly qualified world champio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14819</th>\n",
       "      <td>ukraine puzzled lack u response request ha mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>u president donald trump said friday washingto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9013</th>\n",
       "      <td>stayed close obama family president barack oba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16082</th>\n",
       "      <td>president trump scheduled deliver historic spe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "2283   wayde van niekerk duly qualified world champio...\n",
       "14819  ukraine puzzled lack u response request ha mad...\n",
       "12196  u president donald trump said friday washingto...\n",
       "9013   stayed close obama family president barack oba...\n",
       "16082  president trump scheduled deliver historic spe..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xtest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000017</th>\n",
       "      <th>000063</th>\n",
       "      <th>00007</th>\n",
       "      <th>00042</th>\n",
       "      <th>000938</th>\n",
       "      <th>000a</th>\n",
       "      <th>000after</th>\n",
       "      <th>...</th>\n",
       "      <th>zzg91b1ax8</th>\n",
       "      <th>zzn3bqnfsk</th>\n",
       "      <th>zzqvyk8xif</th>\n",
       "      <th>zztaine</th>\n",
       "      <th>zzucqevt3m</th>\n",
       "      <th>zzuml4hkoc</th>\n",
       "      <th>zzzzaaaacccchhh</th>\n",
       "      <th>zzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzz</th>\n",
       "      <th>émigré</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31423</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31424</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31425</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31426</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31427</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31428 rows × 103540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00       000  0000  00000017  000063  00007  00042  000938  000a  \\\n",
       "0      0.0  0.000000   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "1      0.0  0.000000   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "2      0.0  0.000000   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "3      0.0  0.000000   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "4      0.0  0.000000   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "...    ...       ...   ...       ...     ...    ...    ...     ...   ...   \n",
       "31423  0.0  0.013943   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "31424  0.0  0.000000   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "31425  0.0  0.000000   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "31426  0.0  0.000000   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "31427  0.0  0.000000   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "\n",
       "       000after  ...  zzg91b1ax8  zzn3bqnfsk  zzqvyk8xif  zztaine  zzucqevt3m  \\\n",
       "0           0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "1           0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "2           0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "3           0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "4           0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "...         ...  ...         ...         ...         ...      ...         ...   \n",
       "31423       0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "31424       0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "31425       0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "31426       0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "31427       0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "\n",
       "       zzuml4hkoc  zzzzaaaacccchhh  zzzzzzzz  zzzzzzzzzzzzz  émigré  \n",
       "0             0.0              0.0       0.0            0.0     0.0  \n",
       "1             0.0              0.0       0.0            0.0     0.0  \n",
       "2             0.0              0.0       0.0            0.0     0.0  \n",
       "3             0.0              0.0       0.0            0.0     0.0  \n",
       "4             0.0              0.0       0.0            0.0     0.0  \n",
       "...           ...              ...       ...            ...     ...  \n",
       "31423         0.0              0.0       0.0            0.0     0.0  \n",
       "31424         0.0              0.0       0.0            0.0     0.0  \n",
       "31425         0.0              0.0       0.0            0.0     0.0  \n",
       "31426         0.0              0.0       0.0            0.0     0.0  \n",
       "31427         0.0              0.0       0.0            0.0     0.0  \n",
       "\n",
       "[31428 rows x 103540 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf vectorizer\n",
    "# we must .fit() the vectorizer on the training dataset so that when we use .transform()\n",
    "# the dimension of the resulting df is the same for train and test (it uses the word corpus of training set)\n",
    "# output_train/test is the sparce matrix, df_xtrain/testvectorized is just for display\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(df_xtrain[\"text\"]) \n",
    "output_train = tfidf.transform(df_xtrain[\"text\"])\n",
    "df_xtrainvectorized = pd.DataFrame(output_train.toarray(), columns=tfidf.get_feature_names())\n",
    "df_xtrainvectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000017</th>\n",
       "      <th>000063</th>\n",
       "      <th>00007</th>\n",
       "      <th>00042</th>\n",
       "      <th>000938</th>\n",
       "      <th>000a</th>\n",
       "      <th>000after</th>\n",
       "      <th>...</th>\n",
       "      <th>zzg91b1ax8</th>\n",
       "      <th>zzn3bqnfsk</th>\n",
       "      <th>zzqvyk8xif</th>\n",
       "      <th>zztaine</th>\n",
       "      <th>zzucqevt3m</th>\n",
       "      <th>zzuml4hkoc</th>\n",
       "      <th>zzzzaaaacccchhh</th>\n",
       "      <th>zzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzzzz</th>\n",
       "      <th>émigré</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.086039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13465</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13466</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13467</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13468</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13469</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13470 rows × 103540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             00  000  0000  00000017  000063  00007  00042  000938  000a  \\\n",
       "0      0.000000  0.0   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "1      0.000000  0.0   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "2      0.000000  0.0   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "3      0.000000  0.0   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "4      0.086039  0.0   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "...         ...  ...   ...       ...     ...    ...    ...     ...   ...   \n",
       "13465  0.000000  0.0   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "13466  0.000000  0.0   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "13467  0.000000  0.0   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "13468  0.000000  0.0   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "13469  0.000000  0.0   0.0       0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "\n",
       "       000after  ...  zzg91b1ax8  zzn3bqnfsk  zzqvyk8xif  zztaine  zzucqevt3m  \\\n",
       "0           0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "1           0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "2           0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "3           0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "4           0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "...         ...  ...         ...         ...         ...      ...         ...   \n",
       "13465       0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "13466       0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "13467       0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "13468       0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "13469       0.0  ...         0.0         0.0         0.0      0.0         0.0   \n",
       "\n",
       "       zzuml4hkoc  zzzzaaaacccchhh  zzzzzzzz  zzzzzzzzzzzzz  émigré  \n",
       "0             0.0              0.0       0.0            0.0     0.0  \n",
       "1             0.0              0.0       0.0            0.0     0.0  \n",
       "2             0.0              0.0       0.0            0.0     0.0  \n",
       "3             0.0              0.0       0.0            0.0     0.0  \n",
       "4             0.0              0.0       0.0            0.0     0.0  \n",
       "...           ...              ...       ...            ...     ...  \n",
       "13465         0.0              0.0       0.0            0.0     0.0  \n",
       "13466         0.0              0.0       0.0            0.0     0.0  \n",
       "13467         0.0              0.0       0.0            0.0     0.0  \n",
       "13468         0.0              0.0       0.0            0.0     0.0  \n",
       "13469         0.0              0.0       0.0            0.0     0.0  \n",
       "\n",
       "[13470 rows x 103540 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test = tfidf.transform(df_xtest[\"text\"])\n",
    "df_xtest_vectorized = pd.DataFrame(output_test.toarray(), columns=tfidf.get_feature_names())\n",
    "df_xtest_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Model\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(output_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDT = dt.predict(output_test)\n",
    "resultDT = resultDT.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Decision Tree\n",
      "Predicted     0     1    All\n",
      "True                        \n",
      "0          6825   252   7077\n",
      "1           388  6005   6393\n",
      "All        7213  6257  13470\n"
     ]
    }
   ],
   "source": [
    "#Displaying the confusion matrix\n",
    "print('Confusion Matrix - Decision Tree')\n",
    "print(pd.crosstab(y_test, resultDT, rownames = ['True'], colnames = ['Predicted'], margins = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score - Decision Tree:\n",
      "0.9523102752968575\n"
     ]
    }
   ],
   "source": [
    "print('F1 score - Decision Tree:')\n",
    "print(f1_score(y_test, resultDT, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=20, random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_regr = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "rf_regr.fit(output_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultRF = rf_regr.predict(output_test)\n",
    "resultRF = resultRF.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Random Forest\n",
      "Predicted   0.0   1.0    All\n",
      "True                        \n",
      "0          6937   140   7077\n",
      "1           246  6147   6393\n",
      "All        7183  6287  13470\n"
     ]
    }
   ],
   "source": [
    "#Displaying the confusion matrix\n",
    "print('Confusion Matrix - Random Forest')\n",
    "print(pd.crosstab(y_test, resultRF, rownames = ['True'], colnames = ['Predicted'], margins = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score - Random Forest:\n",
      "0.9712448179593931\n"
     ]
    }
   ],
   "source": [
    "print('F1 score - Random Forest:')\n",
    "print(f1_score(y_test, resultRF, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=20, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost Model\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=20, random_state=0)\n",
    "xgb.fit(output_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultXGB = xgb.predict(output_test)\n",
    "resultXGB = resultXGB.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - XGBClassifier\n",
      "Predicted     0     1    All\n",
      "True                        \n",
      "0          6893   184   7077\n",
      "1           202  6191   6393\n",
      "All        7095  6375  13470\n"
     ]
    }
   ],
   "source": [
    "#Displaying the confusion matrix\n",
    "print('Confusion Matrix - XGBClassifier')\n",
    "print(pd.crosstab(y_test, resultXGB, rownames = ['True'], colnames = ['Predicted'], margins = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score - XGBClassifier:\n",
      "0.9712656827292618\n"
     ]
    }
   ],
   "source": [
    "print('F1 score - XGBClassifier:')\n",
    "print(f1_score(y_test, resultXGB, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Classifier (Note: Extremely long train time, do not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking classifier with naive bayes and decision trees as base learners then log reg as final estimator.\n",
    "\n",
    "estimators = [\n",
    "    ('nb', MultinomialNB()),\n",
    "    ('dt', tree.DecisionTreeClassifier())\n",
    "]\n",
    "    \n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking.fit(output_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultStacking = stacking.predict(output_test)\n",
    "resultStacking = resultStacking.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the confusion matrix\n",
    "print('Confusion Matrix - Stacking Classifier')\n",
    "print(pd.crosstab(y_test, resultStacking, rownames = ['True'], colnames = ['Predicted'], margins = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 score - Stacking Classifier:')\n",
    "print(f1_score(y_test, resultStacking, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
